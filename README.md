# Taylor videos

Using Taylor videos is a simple two-step process.

- To extract Taylor video, simply run `taylor-video.ipynb`.
- To use Taylor videos for action recognition, simply follow [open-mmlab/mmaction2](https://github.com/open-mmlab/mmaction2?tab=readme-ov-file):
  - Environmental setup: [Installation](https://mmaction2.readthedocs.io/en/latest/get_started/installation.html).
  - Pretrained models: [MMAction2 Model Zoo](https://mmaction2.readthedocs.io/en/latest/model_zoo/modelzoo.html).
 
## Videos

<table>
  <tr>
    <td align="center"><a href="video_link_1"><img src="thumbnail_1.jpg" width="250px"></a></td>
    <td align="center"><a href="video_link_2"><img src="thumbnail_2.jpg" width="250px"></a></td>
    <td align="center"><a href="video_link_3"><img src="thumbnail_3.jpg" width="250px"></a></td>
    <td align="center"><a href="video_link_4"><img src="thumbnail_4.jpg" width="250px"></a></td>
  </tr>
  <tr>
    <td align="center"><a href="video_link_5"><img src="thumbnail_5.jpg" width="250px"></a></td>
    <td align="center"><a href="video_link_6"><img src="thumbnail_6.jpg" width="250px"></a></td>
    <td align="center"><a href="video_link_7"><img src="thumbnail_7.jpg" width="250px"></a></td>
    <td align="center"><a href="video_link_8"><img src="thumbnail_8.jpg" width="250px"></a></td>
  </tr>
</table>

 
You can cite the following paper for the use of this work:

```
@misc{wang2024taylor,
      title={Taylor Videos for Action Recognition}, 
      author={Lei Wang and Xiuyuan Yuan and Tom Gedeon and Liang Zheng},
      year={2024},
      eprint={2402.03019},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
```
