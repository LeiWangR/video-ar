{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8e748916",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import os\n",
    "import torch\n",
    "import math\n",
    "import numpy as np\n",
    "import torchvision\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "0c1a6cbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "bpath = os.path.abspath(os.getcwd())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c15ddc93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def taylorvideo(video_path, terms, window_size, step_size):\n",
    "    \n",
    "    if window_size - 3 < terms:\n",
    "        print(\"The given temporal block length is not enough to compute K terms.\")\n",
    "        \n",
    "    else:\n",
    "        vidcap = cv2.VideoCapture(video_path)\n",
    "        \n",
    "        fps = vidcap.get(cv2.CAP_PROP_FPS)\n",
    "        vlen = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "        print(\"Video length: %d\" % vlen, \" |  FPS: %d\" % fps)\n",
    "        \n",
    "        success, image = vidcap.read()\n",
    "        count = 1\n",
    "        while success:\n",
    "            \n",
    "            if count < window_size:\n",
    "                success,image = vidcap.read()\n",
    "                count += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ca3d8762",
   "metadata": {},
   "outputs": [],
   "source": [
    "def videoConvert(vid_path,o,terms,tPrime):\n",
    "    if (tPrime <= terms+3):\n",
    "        tPrime = terms + 3\n",
    "    cap = cv2.VideoCapture(vid_path)\n",
    "    fpsT = cap.get(cv2.CAP_PROP_FPS)\n",
    "    vidlength = int(cap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "    print(\"length = \", vidlength)\n",
    "    print(\"fps = \", fpsT)\n",
    "    ret,frame = cap.read()\n",
    "    norm_g = torch.from_numpy(cv2.cvtColor(frame,  cv2.COLOR_BGR2GRAY))\n",
    "    norm_g = torch.div(norm_g, 255.0)\n",
    "    h, w = norm_g.shape\n",
    "    \n",
    "    length = terms + 3\n",
    "    full_difference_list = torch.zeros((length,length,h,w), dtype=torch.float64)\n",
    "    full_difference_list[0,0,:,:] = norm_g\n",
    "\n",
    "    for initialInc in range(1,terms+3):\n",
    "        ret, frame = cap.read()\n",
    "        norm_g = torch.from_numpy(cv2.cvtColor(frame,  cv2.COLOR_BGR2GRAY))\n",
    "        norm_g = torch.div(norm_g, 255.0)\n",
    "        full_difference_list[0,initialInc,:,:] = norm_g\n",
    "\n",
    "    img = torch.zeros(((vidlength-tPrime+1),h,w,3), dtype=torch.float64)\n",
    "    \n",
    "    for sequences in range(0,vidlength-tPrime+1):\n",
    "        if sequences == 0:\n",
    "            for listInc in range(1,terms+3):\n",
    "                full_difference_list[listInc,:,:,:] = torch.nn.functional.pad((full_difference_list[listInc-1,1:,:,:]-full_difference_list[listInc-1,:-1,:,:]),(0,0,0,0,0,1))\n",
    "        if sequences != 0:\n",
    "            ret, frame = cap.read()\n",
    "\n",
    "            full_difference_list = torch.roll(full_difference_list, -1, 1)\n",
    "            \n",
    "            norm_g = torch.from_numpy(cv2.cvtColor(frame,  cv2.COLOR_BGR2GRAY))\n",
    "            norm_g = torch.div(norm_g, 255.0)\n",
    "            full_difference_list[0,length-1,:,:] = norm_g\n",
    "            for listInc in range(1,terms+3):\n",
    "                full_difference_list[listInc,length-1-listInc,:,:] = full_difference_list[listInc-1,length-listInc,:,:] - full_difference_list[listInc-1,length-1-listInc,:,:]\n",
    "        \n",
    "        t1Sum = 0\n",
    "        t2Sum = 0\n",
    "        t3Sum = 0\n",
    "\n",
    "        dummy = full_difference_list[0,0,:,:].unsqueeze(0).repeat(length, 1, 1)\n",
    "        xa_Tensor =  full_difference_list[0,:,:,:] - dummy\n",
    "\n",
    "        for incB in range(0,terms):\n",
    "            part = torch.div(torch.pow(xa_Tensor,incB), math.factorial(incB))\n",
    "            t1Sum += torch.mul(torch.sum(part,0),full_difference_list[incB+1,0,:,:])\n",
    "            t2Sum += torch.mul(torch.sum(part,0),full_difference_list[incB+2,0,:,:])\n",
    "            t3Sum += torch.mul(torch.sum(part,0),full_difference_list[incB+3,0,:,:])\n",
    "\n",
    "        # R channel\n",
    "        img[sequences,:,:,0] = t1Sum \n",
    "        # G channel\n",
    "        img[sequences,:,:,1] = t2Sum \n",
    "        # B channel\n",
    "        img[sequences,:,:,2] = t3Sum\n",
    "    cap.release()\n",
    "\n",
    "    torchvision.io.write_video(filename=o, video_array=img, fps=fpsT, video_codec='h264')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8561b019",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "length =  116\n",
      "fps =  24.0\n"
     ]
    }
   ],
   "source": [
    "videoConvert(\"brush.mp4\",\"brush-taylor.mp4\",5,0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b62a1d6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
